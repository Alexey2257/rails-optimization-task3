# Case-study оптимизации

## Актуальная проблемы
A. Импорт данных
При выполнении bin/setup в базу данных загружаются данные о рейсах из файла fixtures/small.json
Сама загрузка данных из файла делается очень наивно (и не эффективно).
В комплекте с заданием поставляются файлы
Нужно оптимизировать механизм перезагрузки расписания из файла так, чтобы он импортировал файл large.json в пределах минуты.
rake reload_json[fixtures/large.json]

Б. Отображение расписаний
Сами страницы расписаний тоже формируются не эффективно и при росте объёмов начинают сильно тормозить.
Нужно найти и устранить проблемы, замедляющие формирование этих страниц.

## Часть А

### Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время импорта файла large.json

### Гарантия корректности работы оптимизированной программы
Для проверки корректной работы программе в начале я написал тест. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
Дополнительно в тест я добавил защиту от регрессии времени работы программы, обновляя значение после каждого шага

### Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за ~ 10 секунд

Вот как я построил `feedback_loop`:
Для начала я взял файл small.json
- Прогоняется тест корректности работы и производительности
- Выполняется профилирование
- По результатам профилирования ищется главная точка роста
- Вносятся правки в код, прогоняются тесты, если тесты не упали и точка роста поменялась то апдейчу тесты и ищу новую точку роста

### Вникаем в детали системы, чтобы найти главные точки роста
Вот какие проблемы удалось найти и решить

#### Ваша находка №1
- Согласно плану работы сначала было решено использовать activerecord-import для импорта файлов
- Я переделал процесс импорта файла, теперь поездки сохраняются с помощью activerecord-import. Кроме того, я сделал накапливание айдишников объектов, чтобы убрать лишние обращения к базе.
- 6.1 секунд -> 2.5 секунды для файла small.json. medium.json 6.1 секунды, large.json 23 секунды.
- В целом уже удалось уложиться в бюджет, но для интереса можно попрофилировать

### Ваша находка №2
- Рубипроф и мемори профайлер выдавали нечитаемые отчеты из-за запуска таски в енвайронменте рельсов. Я решил попробовать сократить использование памяти
- Вместо того чтобы собирать объекты через Trip.new в отдельный массив, я использую map при пробеге по джсону чтобы собрать аргументы и затем использользовать их для импорта
- 23 секунды -> 15 секунд для файла large.json
- 

### Ваша находка №X
- Посмотрел по memory_profiler какие еще есть подозрительные места. Главной точкой роста оставался String#split но тут не удалось особо оптимизировать.
- Убрал лишние присваивания, использовал bang-методы там где возможно
- 29Мб -> 28Мб, разницы почти нет
- Почти не изменился

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 104 мб для 10_000 строк на 28 мб для любого количества строк и уложиться в заданный бюджет.

По сравнению с результатом выполнения первого домашнего задания скорость работы программы улучилась почти в три раза -- с 23 секунд до 8.5

valgrind massif visualizer показывает что пиковое потребление памяти 40Мб

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были написаны автотесты производительности и аллокации памяти
